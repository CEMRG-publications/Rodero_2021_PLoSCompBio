import numpy as np

def main():
	# result of doing: "for i in {0..34}; do cat ${i}/r2_split_test_scores.txt; done"
	r2_scores = np.array([0.993154, 0.987729, 0.998363, 0.999773, 0.998970, 0.061294, -0.040380, -0.111734, 0.096807, -0.352146, -1.249997, -0.370735, -0.547857, -1.097474, 0.130806, 0.967238, 0.991168, 0.952116, 0.968006, 0.995098, 0.284778, 0.824001, 0.771408, 0.941749, 0.152084, 0.412682, 0.629560, 0.567861, 0.764264, 0.317024, -1.089801, -0.425323, 0.353634, -0.678846, 0.516791, 0.218197, 0.520283, 0.686702, 0.169069, 0.425518, 0.201394, 0.880625, 0.653504, 0.285011, 0.643965, 0.683319, 0.787785, 0.902224, 0.374704, -0.266400, 0.729604, 0.934064, 0.754149, 0.577853, 0.502975, 0.970582, 0.971687, 0.998747, 0.995972, 0.995551, -1.557717, 0.911967, 0.698636, 0.053933, 0.357730, -0.298587, -0.851631, 0.892033, -0.377794, 0.330367, 0.988826, 0.974249, 0.969791, 0.958222, 0.989288, 0.940607, 0.936684, 0.838113, 0.774025, 0.186459, -12.311382, -1.288111, 0.203486, -0.384044, -0.047139, -14.369257, -5.453203, 0.639469, -0.447004, -0.446491, -11.746472, -1.064187, 0.670587, -0.356072, -0.280592, 0.949645, 0.969174, 0.909989, 0.999826, 0.661626, -5.452212, -15.148230, -0.499886, -0.112576, -0.499526, -0.905329, 0.333665, -9.601368, 0.778537, -0.316431, 0.969855, 0.984570, 0.933335, 0.999464, 0.904376, 0.961985, 0.981358, 0.858599, 0.927288, 0.969581, -0.171505, 0.531223, 0.782483, 0.004059, 0.517429, -7204497246.806396, -2.801382, 0.442143, 0.033719, 0.194730, -2.182754, 0.087273, 0.813721, -0.028957, 0.614319, -4.983768, 0.712129, 0.297051, 0.016379, 0.385272, 0.544233, 0.050316, 0.475355, 0.372010, -0.249995, -0.955019, 0.251409, 0.675851, -0.507454, 0.287560, 0.886872, 0.945650, 0.863488, 0.984622, -0.285392, -15.493257, 0.895169, 0.621018, -0.016593, 0.352050, -1.949286, 0.173178, 0.656825, -0.073953, 0.428469, 0.922612, 0.987791, 0.934645, -0.062091, -0.912512, -0.317980, 0.928845, 0.174541, -0.339377, 0.401783])

	# gather cross-validation scores for each feature
	r2_split_test_scores = []
	for i in range(35):
		r2_split_test_scores.append(r2_scores[5*i:5*(i+1)])

	# make stats dictinary
	features = ['EDV_LV', 'Myo_vol_LV', 'ESP_LV', 'ESV_LV', 'EF_LV', 'ET_LV', 'ICT_LV', 'IRT_LV', 'dPdtmax_LV', 'dPdtmin_LV', 'PeakP_LV', 'SV_LV', 'tpeak_LV', 'tsys_LV', 'V1_LV', 'EF1_LV', 'QRS_LV', 'AT1090_LV', 'AT_LV', 'EDV_RV', 'Myo_vol_RV', 'ESP_RV', 'ESV_RV', 'EF_RV', 'ET_RV', 'ICT_RV', 'IRT_RV', 'dPdtmax_RV', 'dPdtmin_RV', 'PeakP_RV', 'SV_RV', 'tpeak_RV', 'tsys_RV', 'V1_RV', 'EF1_RV']
	stats_dict = {key: list(r2_split_test_scores[i]) for i, key in enumerate(features)}

	# if all the r2 split test scores are negative for one predicted feature, gpes are not reliable to be used for GSA
	discard = []
	for key in stats_dict.keys():
		if (not (np.sign(stats_dict[key]) > 0).any()) or (np.mean(stats_dict[key]) < 0):
			discard.append(key)

	print("Discard")
	print(discard)


if __name__ == '__main__':
	main()